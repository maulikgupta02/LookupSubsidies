{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_govt=soup.find('section',id='Central')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head=state_govt.find_next('tr')\n",
    "# header=head.find_all('th')\n",
    "# header_list=[header[i].text.split(\"\\r\\n\")[1].strip() for i in range(len(header))]\n",
    "# header_list=['Sr No',\n",
    "#  'Subsidy scheme',\n",
    "#  'Scheme Type',\n",
    "#  'Ministry',\n",
    "#  'Description',\n",
    "#  'Visiting link to know more',\n",
    "#  'Applicability Central/State']\n",
    "\n",
    "# dic={}\n",
    "# for j in header_list:\n",
    "#     dic[j]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsidy_data(ID,dic):\n",
    "    govt=soup.find('section',id=ID)\n",
    "    head=govt.find_next('tr')\n",
    "    header=head.find_all('th')\n",
    "\n",
    "    pointer=head.find_next('tr')\n",
    "    while pointer:\n",
    "        try:\n",
    "            row=pointer.find_all(\"td\")\n",
    "            dic[\"Sr No\"].append(row[0].text.strip())\n",
    "            dic[\"Subsidy scheme\"].append(row[1].text.strip())\n",
    "            dic[\"Scheme Type\"].append(row[2].text.strip())\n",
    "            dic[\"Ministry\"].append(row[3].text.strip())\n",
    "            dic[\"Description\"].append(row[4:len(row)-2][0].text.strip())\n",
    "            dic['Visiting link to know more'].append(row[-2].text.strip())\n",
    "            dic['Applicability Central/State'].append(row[-1].text.strip())\n",
    "\n",
    "            skip_rows_count=0\n",
    "            tab=pointer.find_next('table')\n",
    "            for _ in range(len(pointer.find_all('table'))):\n",
    "                skip_rows_count+=len(tab.find_all('tr'))\n",
    "                tab=tab.find_next('table')\n",
    "            # script to extract table in csv format\n",
    "\n",
    "            # while table:\n",
    "            #     # print(table)\n",
    "            #     headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
    "            #     rows = []\n",
    "            #     for tr in table.find_all('tr')[1:]:\n",
    "            #         cells = tr.find_all('td')\n",
    "            #         row = [cell.get_text(separator='\\n', strip=True) for cell in cells]\n",
    "            #         rows.append(row)\n",
    "            #     print(rows)\n",
    "            #     df=pd.DataFrame(rows,columns=headers)\n",
    "            #     df.to_csv(\"temp.csv\",index=False)\n",
    "            #     print(df)\n",
    "            #     table=table.find_next('table')\n",
    "\n",
    "            for _ in range(skip_rows_count+1):\n",
    "                pointer=pointer.find_next('tr')\n",
    "        except Exception:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\Desktop\\policies\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.standupmitra.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\gupta\\Desktop\\policies\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.standupmitra.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\gupta\\Desktop\\policies\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.standupmitra.in'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "categories=[\"Women\",\"All\",\"SCST\"]\n",
    "\n",
    "header_list=['Sr No',\n",
    " 'Subsidy scheme',\n",
    " 'Scheme Type',\n",
    " 'Ministry',\n",
    " 'Description',\n",
    " 'Visiting link to know more',\n",
    " 'Applicability Central/State']\n",
    "\n",
    "dic={}\n",
    "for j in header_list:\n",
    "    dic[j]=[]\n",
    "\n",
    "for cat in categories:\n",
    "    url = f'https://www.standupmitra.in/Home/SubsidySchemesFor{cat}'\n",
    "    response = requests.get(url, verify=False)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for ID in [\"Central\",\"State\"]:\n",
    "        get_subsidy_data(ID=ID,dic=dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(dic)\n",
    "df.to_csv(\"subsidies.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"llama3\") \n",
    "\n",
    "def split_description(subs):\n",
    "    message=f\"\"\"\n",
    "    You are provided with a description of a government subsidy scheme : {subs}\\\n",
    "    Return a list with two elements, first one as the summary of the scheme, and second as the eligibility criteria\\\n",
    "    Give a concise eligibility cirteria.\n",
    "    \"\"\"\n",
    "\n",
    "    response=model.invoke(message).split(\"**\")\n",
    "    summary=response[2].strip(\" \\n*\")\n",
    "    criteria=response[4].strip(\" \\n*\")\n",
    "\n",
    "    return summary,criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"subsidies.csv\")\n",
    "\n",
    "summary=[]\n",
    "criteria=[]\n",
    "\n",
    "for _,subsidy in df.iterrows():\n",
    "    response=split_description(subsidy[\"Description\"])\n",
    "    summary.append(response[0])\n",
    "    criteria.append(response[1])\n",
    "\n",
    "df[\"summary\"]=summary\n",
    "df[\"eligibility_criteria\"]=criteria\n",
    "\n",
    "df.to_csv(\"processed_subsidies.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
